{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c5ef22",
   "metadata": {},
   "source": [
    "# Global Health Medical Center -  Bone Fracture Image Classification with PyTorch\n",
    "\n",
    "## Business Scenario\n",
    "\n",
    "In the rapidly evolving field of medical diagnostics, timely and accurate detection of bone fractures can significantly impact patient outcomes and healthcare efficiency. Emergency rooms and clinics around the world are often overwhelmed, leading to delayed diagnoses and increased patient suffering. \n",
    "\n",
    "Imagine a scenario where a state-of-the-art AI system assists medical professionals by providing rapid, reliable, and precise identification of bone fractures from X-ray images. This technology can help reduce diagnostic errors, expedite treatment decisions, and ultimately save lives. By leveraging advanced machine learning techniques and powerful neural networks, this project aims to develop an automated solution for bone fracture detection.\n",
    "\n",
    "This bone fracture classification system can be integrated into existing hospital workflows, assisting radiologists in their decision-making process. It can serve as a second opinion, catching fractures that might be missed during a busy shift or by less experienced practitioners. Additionally, in rural or under-resourced settings, where access to expert radiologists is limited, this AI system can provide critical support, ensuring that patients receive the care they need, when they need it.\n",
    "\n",
    "By leveraging advanced machine learning techniques and a sophisticated convolutional neural network (CNN) architecture, this project seeks to develop a robust and reliable model for bone fracture detection. This AI system will provide significant support in:\n",
    "- **Reducing diagnostic errors**: Acting as a second pair of eyes for radiologists, the system helps catch fractures that might be missed during hectic shifts or by less experienced practitioners.\n",
    "- **Expediting treatment decisions**: Rapid and accurate fracture detection enables quicker treatment initiation, improving patient outcomes.\n",
    "- **Enhancing healthcare accessibility**: In rural or under-resourced settings, where access to expert radiologists is limited, the AI system can provide essential diagnostic support.\n",
    "\n",
    "Welcome to the future of medical diagnostics, where technology and healthcare unite to enhance patient care and streamline medical processes. Let's dive into the development of this groundbreaking bone fracture image classification model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f77b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import numpy as np\n",
    "import deeplake\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6573aa",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "We'll prepare the dataset with data augmentation for the training set and normalization for all sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ae755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/mura-train\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/mura-train loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/mura-val\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/mura-val loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Data transformations with augmentation\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.Resize((224, 224)),  # Resize to a fixed size\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.RandomRotation(10),  # Random rotation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# Load the data\n",
    "mura_train = deeplake.load(\"hub://activeloop/mura-train\")\n",
    "mura_val = deeplake.load(\"hub://activeloop/mura-val\")\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root='bonedata/test', transform=val_test_transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = mura_train.pytorch(num_workers = 8, \n",
    "                                shuffle = True, \n",
    "                                transform = {'images': train_transform, 'study_type': None}, \n",
    "                                batch_size = 64, \n",
    "                                decode_method = {'images': 'pil'})\n",
    "\n",
    "\n",
    "val_loader = mura_val.pytorch(num_workers = 8, \n",
    "                                shuffle = False, \n",
    "                                transform = {'images': val_test_transform, 'study_type': None}, \n",
    "                                batch_size = 64, \n",
    "                                decode_method = {'images': 'pil'})\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef75e44",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "We'll use a pre-trained ResNet model and fine-tune it for our specific task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca78630",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights = models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Modify the first convolutional layer to accept single-channel input\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "# Modify the final layer to match the number of classes (binary classification in this case)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836678a9",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer\n",
    "\n",
    "We'll use the Cross Entropy Loss and the Adam optimizer. A learning rate scheduler will also be used to adjust the learning rate during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f5d4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c347dfb",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We'll train the model for a set number of epochs, evaluate it on the validation set, and adjust the learning rate using the scheduler.\n",
    "\n",
    "let's first define a function for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404e0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, optimizer, train_loader, val_loader, criterion, device):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "            inputs = data['images']\n",
    "            labels = torch.squeeze(data['study_type'])\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "  \n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = train_correct / len(train_loader.dataset)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for j, val_data in enumerate(val_loader):\n",
    "         \n",
    "                val_inputs = val_data['images']\n",
    "                val_labels = torch.squeeze(val_data['study_type'])\n",
    "\n",
    "                val_inputs = val_inputs.to(device)\n",
    "                val_labels = val_labels.to(device)\n",
    "                val_outputs  = model(val_inputs.float())\n",
    "                loss = criterion(val_outputs, val_labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(val_outputs, 1)\n",
    "                val_correct += (predicted == val_labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = val_correct / len(val_loader.dataset)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
    "          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "    return train_accuracy, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44231ada",
   "metadata": {},
   "source": [
    "now let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47993910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Training Epoch 1 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:01<00:00, 6.78MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 1/25, Train Loss: 0.6214, Train Accuracy: 0.6628, Validation Loss: 0.6584, Validation Accuracy: 0.6333\n",
      "------------------ Training Epoch 2 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:00<00:00, 6.81MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 2/25, Train Loss: 0.5587, Train Accuracy: 0.7141, Validation Loss: 0.5913, Validation Accuracy: 0.7018\n",
      "------------------ Training Epoch 3 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:11<00:00, 6.58MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 3/25, Train Loss: 0.5372, Train Accuracy: 0.7345, Validation Loss: 0.5645, Validation Accuracy: 0.7069\n",
      "------------------ Training Epoch 4 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [06:41<00:00, 5.10MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 4/25, Train Loss: 0.5207, Train Accuracy: 0.7466, Validation Loss: 0.5347, Validation Accuracy: 0.7297\n",
      "------------------ Training Epoch 5 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [04:42<00:00, 7.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 5/25, Train Loss: 0.5070, Train Accuracy: 0.7571, Validation Loss: 0.5940, Validation Accuracy: 0.6894\n",
      "------------------ Training Epoch 6 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:24<00:00, 6.30MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 6/25, Train Loss: 0.4967, Train Accuracy: 0.7639, Validation Loss: 0.5160, Validation Accuracy: 0.7525\n",
      "------------------ Training Epoch 7 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:10<00:00, 6.60MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 7/25, Train Loss: 0.4876, Train Accuracy: 0.7707, Validation Loss: 0.5499, Validation Accuracy: 0.7300\n",
      "------------------ Training Epoch 8 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [04:58<00:00, 6.86MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 8/25, Train Loss: 0.4480, Train Accuracy: 0.7977, Validation Loss: 0.4929, Validation Accuracy: 0.7730\n",
      "------------------ Training Epoch 9 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:01<00:00, 6.79MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 9/25, Train Loss: 0.4347, Train Accuracy: 0.8068, Validation Loss: 0.4890, Validation Accuracy: 0.7790\n",
      "------------------ Training Epoch 10 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:44<00:00, 5.95MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 10/25, Train Loss: 0.4264, Train Accuracy: 0.8118, Validation Loss: 0.4825, Validation Accuracy: 0.7801\n",
      "------------------ Training Epoch 11 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:05<00:00, 6.71MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 11/25, Train Loss: 0.4206, Train Accuracy: 0.8157, Validation Loss: 0.4920, Validation Accuracy: 0.7811\n",
      "------------------ Training Epoch 12 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [04:44<00:00, 7.21MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 12/25, Train Loss: 0.4129, Train Accuracy: 0.8191, Validation Loss: 0.4831, Validation Accuracy: 0.7854\n",
      "------------------ Training Epoch 13 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:48<00:00, 5.87MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 13/25, Train Loss: 0.4053, Train Accuracy: 0.8227, Validation Loss: 0.4835, Validation Accuracy: 0.7851\n",
      "------------------ Training Epoch 14 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [04:53<00:00, 6.98MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 14/25, Train Loss: 0.3994, Train Accuracy: 0.8266, Validation Loss: 0.4870, Validation Accuracy: 0.7811\n",
      "------------------ Training Epoch 15 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [04:54<00:00, 6.96MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 15/25, Train Loss: 0.3867, Train Accuracy: 0.8322, Validation Loss: 0.4867, Validation Accuracy: 0.7915\n",
      "------------------ Training Epoch 16 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:14<00:00, 6.52MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 16/25, Train Loss: 0.3814, Train Accuracy: 0.8370, Validation Loss: 0.4859, Validation Accuracy: 0.7874\n",
      "------------------ Training Epoch 17 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:17<00:00, 6.46MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 17/25, Train Loss: 0.3828, Train Accuracy: 0.8351, Validation Loss: 0.4897, Validation Accuracy: 0.7854\n",
      "------------------ Training Epoch 18 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:03<00:00, 6.74MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 18/25, Train Loss: 0.3772, Train Accuracy: 0.8381, Validation Loss: 0.4898, Validation Accuracy: 0.7881\n",
      "------------------ Training Epoch 19 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [05:10<00:00, 6.60MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 19/25, Train Loss: 0.3777, Train Accuracy: 0.8371, Validation Loss: 0.4926, Validation Accuracy: 0.7837\n",
      "------------------ Training Epoch 20 /25 ------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.: 100%|██████████████████▉| 1.91G/1.91G [04:52<00:00, 6.99MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Epoch 20/25, Train Loss: 0.3771, Train Accuracy: 0.8392, Validation Loss: 0.4860, Validation Accuracy: 0.7908\n",
      "Early stopping triggered\n",
      "Total training time: 6.72 hours\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "training_start_time = time.time()\n",
    "\n",
    "#variables for implementing early stopping\n",
    "patience = 5 # this variable is to apply early stopping technique\n",
    "best_val_accuracy = 0.0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"------------------ Training Epoch {epoch+1} /{num_epochs} ------------------\")\n",
    "    train_accuracy, val_accuracy = model_train(model, optimizer, train_loader, val_loader, criterion, device)\n",
    "    \n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    #If statement for early stopping mechanism\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "    \n",
    "    \n",
    "training_end_time = time.time()\n",
    "\n",
    "# Calculate the total training time in hours\n",
    "total_training_time = (training_end_time - training_start_time) /3600\n",
    "print(f\"Total training time: {total_training_time:.2f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58bd105",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we built an advanced image classification model using a pre-trained ResNet and fine-tuned it to detect bone fractures. We used data augmentation, a learning rate scheduler, and evaluated the model on separate training, validation, and test sets to ensure robust performance. We also deployed the model on hugging face (deployment code is in seperate notebook)  to test individual images for fracture predictions, making this project a comprehensive and practical tool for bone fracture detection.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
